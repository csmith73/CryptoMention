import sqlite3
import string
import threading
import time
from collections import Counter
from datetime import datetime

import praw
from nltk.corpus import stopwords
from nltk.tokenize import RegexpTokenizer

from CryptoMention.Import_words import tot_list, test_list


class RepeatedTimer(object):
  def __init__(self, interval, function, *args, **kwargs):
    self._timer = None
    self.interval = interval
    self.function = function
    self.args = args
    self.kwargs = kwargs
    self.is_running = False
    self.next_call = time.time()
    self.start()

  def _run(self):
    self.is_running = False
    self.start()
    self.function(*self.args, **self.kwargs)

  def start(self):
    if not self.is_running:
      self.next_call += self.interval
      self._timer = threading.Timer(self.next_call - time.time(), self._run)
      self._timer.start()
      self.is_running = True

  def stop(self):
    self._timer.cancel()
    self.is_running = False

#Initialize the reddit api wrapper praw
reddit = praw.Reddit('bot1')

#Start a counter to accumulate word counts locally
counter = Counter()
#List of puncuation to discard
punct = list(string.punctuation)
#Excluded word lists
excluded_words = ['the','like','/"','/’',"'ve","/’"]
stopword_list = stopwords.words('english') + punct + ['rt', 'via'] + ['...','http','https','I',"``","'s","n't","'ll","'re","'m","--","/'",'crypto','money','get','top','good','big','yes','high','best','way','read','time','day','token','hold','ride','play','stress','bot','trust','pay','moon','team','fuck','status','soon']
coins_monitored = []
#Remove all unwanted words from the tokens generated by nltk
def process(text,stopwords=[]):
    text = text.lower()
    translate_table = dict((ord(char), None) for char in string.punctuation)
    text = text.translate(translate_table)
    print(text)
    tokenizer = RegexpTokenizer(r'\w+')
    tokens = tokenizer.tokenize(text)
    print('All Words: '+ str(tokens))
    tokens = [word1 for word1 in tokens if word1 in tot_list and len(word1)> 2]
    print('Coins Only: ' + str(tokens))
    return [word for word in tokens if word not in stopwords and not word.isdigit()]

def find_key_words(text):
    return[word1 for word1 in text if word1 in test_list]


#Update word counts to the sqlite db every minute and clear local counter cache
def write_db(list):
    sqlite_file = 'wordfreq'
    conn = sqlite3.connect(sqlite_file)
    c = conn.cursor()
    counter_list_sorted = sorted(list, key=lambda pair: pair[1], reverse=True)
    for item in counter_list_sorted:
        #print(item[0], item[1])
        cur_date = datetime.now()
        #c.execute("UPDATE words SET frequency = frequency + ?,date = ? WHERE name = ?", (item[1],cur_date,item[0]))
        #c.execute("INSERT OR IGNORE INTO words (name, frequency, date) VALUES (?, ?, ?)",(item[0], item[1], cur_date))
        c.execute("INSERT INTO words (name, frequency, date) VALUES (?, ?, ?)", (item[0], item[1], cur_date))
    conn.commit()
    conn.close()
    counter.clear()

#Timer to that calls write_db every x minutes
rt = RepeatedTimer(1, write_db, counter.items()) # it auto-starts, no need of rt.start()



#Get comment stream from specific subreddit and create nltk tokens
for comment in reddit.subreddit('CryptoCurrency').stream.comments():
    #print(count)
    tokens = process(comment.body,stopword_list)
    print(tokens)
    counter.update(tokens)



